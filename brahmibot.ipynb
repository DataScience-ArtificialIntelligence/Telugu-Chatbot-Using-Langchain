{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain -q\n",
    "%pip install -qU transformers accelerate einops langchain xformers bitsandbytes\n",
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function To Translate from Telugu to English\n",
    "def translate_telugu_to_english(text):\n",
    "    translator= Translator(to_lang=\"en\", from_lang=\"te\")\n",
    "    translation = translator.translate(text)\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function To Translate from English to Telugu\n",
    "def translate_english_to_telugu(text):\n",
    "    translator= Translator(to_lang=\"te\", from_lang=\"en\")\n",
    "    translation = translator.translate(text)\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model used at the core of the conversation chain is Facebook BlenderBot-400M\n",
    "model_name = 'facebook/blenderbot-400M-distill'\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "tokenizer=transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = transformers.AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Hugging Face Pipeline for responding to text messages, what tokeniser must be used and all are also specified, this pipeline will act as the LLM in LangChain's conversation Chain\n",
    "generate_text = transformers.pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    tokenizer=tokenizer,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template defined using LangChain which will be determining the behavior of the bot\n",
    "template = \"\"\"You are a generic friendly chatbot that answers well and respectfully to humans\n",
    "{question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the nature of Conversation chain using LangChain's LLMChain feature\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt, verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation loop\n",
    "while (True):\n",
    "  dialogue = input(\"user: \")\n",
    "\n",
    "  if dialogue == \"వెళ్ళొస్తాను\" or dialogue == \"ఇక సెలవు\" : # Telugu equivalents of Goodbye\n",
    "    print(\"Chatbot : సంభాషణ ముగిసింది, ధన్యవాదాలు\") # Chatbot breaks loop saying \"Conversation ended, thank you\"\n",
    "    break\n",
    "\n",
    "  english_translation = translate_telugu_to_english(str(dialogue))\n",
    "  print(english_translation, \"\\n\")\n",
    "\n",
    "  response = llm_chain.run(english_translation)\n",
    "  print(response, \"\\n\")\n",
    "\n",
    "  output = (translate_english_to_telugu(response))\n",
    "\n",
    "  print(\"Chatbot : \", output, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
